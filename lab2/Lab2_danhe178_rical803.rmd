---
title: "lab2_danhe178_rical803"
author: "Daniel Herzegh & Richard Friberg"
date: "2017-10-03"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


### Uppgift 1 Likelihoodfunktioner

```{r, echo = TRUE}
set.seed(4711)
x1 <- rgamma(n = 10, shape = 4, scale = 1)
x2 <- rgamma(n = 100, shape = 4, scale = 1)
```

## a)

```{r, echo = TRUE}
llgamma <- function(x, alpha, beta) {
  return(length(x) * (alpha * log(beta) - lgamma(alpha)) + (alpha -1) * sum(log(x)) - beta * sum(x))
}
```

## b)
```{r, echo = TRUE}

beta_tendraws <- c()
beta_hundreddraws <- c()
steps <- c()

i = 0.01
while(i <= 3) {
  tendraws <- c(tendraws, llgamma(x1, alpha = 4, beta = i))
  hundreddraws <- c(hundreddraws, llgamma(x2, alpha = 4, beta = i))
  steps <- c(steps, i)
  i <- i + 0.01
}
```

```{r, echo = TRUE}
# plot for ten draws
plot(steps, tendraws)
```

```{r, echo = TRUE}
# plot for hundred draws
plot(steps, hundreddraws)
```

```{r, echo = TRUE}
# Undersöker och returnerar vilket betavärde som loglikelyhoodfunktionen får sitt maxvärde på
findMaxIndex <- function(vect) {
  i <- NULL
  currentMax <- -Inf
  x <- 1
  while (x < length(vect)) {
    if (vect[x] > currentMax) {
      currentMax <- vect[x]
      i <- x
    }
    x <- x + 1
  }
  return(i/100)
}

findMaxIndex(tendraws)
findMaxIndex(hundreddraws)
```

Det varierar vilket av de upprepade värdena för beta som ger maximala värdet på loglikelihoodfunktionen, men ökar man antalet dragningar går denna siffra mot 1.0.


## c)

```{r, echo = TRUE}

alpha_tendraws <- c()
alpha_hundreddraws <- c()
steps <- c()

i = 0.01
while(i <= 10) {
  tendraws <- c(tendraws, llgamma(x1, alpha = i, beta = 1))
  hundreddraws <- c(hundreddraws, llgamma(x2, alpha = i, beta = 1))
  steps <- c(steps, i)
  i <- i + 0.01
}

```

```{r, echo = TRUE}
# plot for ten draws
plot(steps, tendraws)
```

```{r, echo = TRUE}
# plot for hundred draws
plot(steps, hundreddraws)
```

```{r, echo = TRUE}
# Undersöker och returnerar vilket alphavärde som loglikelyhoodfunktionen får sitt maxvärde på
findMaxIndex <- function(vect) {
  i <- NULL
  currentMax <- -Inf
  x <- 1
  while (x < length(vect)) {
    if (vect[x] > currentMax) {
      currentMax <- vect[x]
      i <- x
    }
    x <- x + 1
  }
  return(i/100)
}

findMaxIndex(tendraws)
findMaxIndex(hundreddraws)
```

Det varierar vilket av de upprepade värdena för alpha som ger maximala värdet på loglikelihoodfunktionen, men ökar man antalet dragningar går denna siffra mot 4.0.


## d) 
### Härledning av log-likelihood för normalfördelning:
![Härledning av log-likelihood för normalfördelning del 1](harledning_1d_1.jpg)
![Härledning av log-likelihood för normalfördelning del 2](harledning_1d_2.jpg)

```{r, echo = TRUE}
```

```{r, echo = TRUE}
llnormal <- function(x, mu, sigma2) {
  xsum <- sum((x - mu)**2)
  return(-length(x)/2*log(2*pi) - length(x)/2 * log(sigma2) - 1/(2 * sigma2) * xsum)
}

llnormal(x = x1, mu = 2, sigma2 = 1) #Fråga om okej

```


## e) 
```{r, echo = TRUE}
mu_tendraws <- c()
mu_hundreddraws <- c()
steps <- c()

i = 0.01
while(i <= 10) {
  tendraws <- c(tendraws, llnormal(x1, mu = i, sigma2 = 1))
  hundreddraws <- c(hundreddraws, llnormal(x2, mu = i, sigma2 = 1))
  steps <- c(steps, i)
  i <- i + 0.01
}

```

```{r, echo = TRUE}
# plot for ten draws
plot(steps, tendraws)
```

```{r, echo = TRUE}
# plot for hundred draws
plot(steps, hundreddraws)
```
```{r, echo = TRUE}
mu_max <- mu_tendraws[findMaxIndex(mu_tendraws)]
alpha_max <- alpha_tendraws[findMaxIndex(alpha_tendraws)]
beta_max <- beta_tendraws[findMaxIndex(beta_tendraws)]
dgamma(x1, )
```

### Uppgift 2 Punktskattning med MLE i en gammafördelning
```{r, echo = TRUE}
gamma_beta_mle <- function(x, alpha) {
  return(length(x)*alpha*1/sum(x))
}
x1 <- rgamma(n = 10, shape = 4, scale = 1)
x2 <- rgamma(n = 100, shape = 4, scale = 1)
gamma_beta_mle(x1, 2)
gamma_beta_mle(x2, 2)
```

Vi testade att öka antalet dragningar och drar slutsatsen att estimatet går mot 0.5



### Uppgift 3 Punktskattning med MLE i en normalfördelning


## a)

```{r, echo = TRUE}
norm_mu_mle <- function(x) {
  return(1/length(x)*sum(x))
}

norm_sigma2_mle <- function(x) {
  sumhelp <- 0
  j <- 1
  while(j <= length(x)) {
    sumhelp <- sumhelp + (x[j] - norm_mu_mle(x))**2
    j <- j + 1 #använd funktion sum
  }
  return(1/length(x)*sumhelp)
}
```


```{r, echo = TRUE}
test_x <- 1:10

norm_mu_mle(x = test_x)

norm_sigma2_mle(x = test_x)

```


## b)

```{r, echo = TRUE}
set.seed(42)
# Skattning med n = 10
y1 <- rnorm(n = 10, mean = 10, sd = 2)

norm_mu_mle(x = y1)


norm_sigma2_mle(x = y1)

# Skattning med n = 10000
y2 <- rnorm(n = 10000, mean = 10, sd = 2)

norm_mu_mle(x = y2)

norm_sigma2_mle(x = y2)
```

Desto större antal dragningar som görs, desto närmare kommer vi mu och sigma2, med respektive norm_mu_mle och norm_sigma2_mle. Detta följer av centralagärnsvärdessatsen som ger oss ett y som går mot normalfördelning och därmed tydligare väntevärde samt varians.





## Uppgift 4 Samplingfördelningen för Bmle, MUmle och sigma2mle


### a)

```{r, echo = TRUE}

beta1_mle <- c(1:2000)
beta2_mle <- c(1:2000)
mu1 <- c(1:2000)
mu2 <- c(1:2000)
sigma1 <- c(1:2000)
sigma2 <- c(1:2000)

i <- 1
while (i <= 2000) {
  x1 <- rgamma(n = 10, shape = 4, rate = 1)
  x2 <- rgamma(n = 10000, shape = 4, rate = 1)
  beta1_mle[i] <- gamma_beta_mle(x = x1, alpha = 4)
  beta2_mle[i] <- gamma_beta_mle(x = x2, alpha = 4)
  
  y1 <- rnorm(n = 10, mean = 10, sd = 2)
  y2 <- rnorm(n = 10000, mean = 10, sd = 2)
  mu1[i] <- norm_mu_mle(x = y1)
  mu2[i] <- norm_mu_mle(x = y2)
  sigma1[i] <- norm_sigma2_mle(x = y1)
  #sigma2[i] <- norm_sigma2_mle(x = y2) #FRÅGA: GÅR LÅNGSAMT. HOW TO MAKE IT GO FASTER??? CAN WE DO THIS BY NOT LOOPING? IF SO, HOW DO WE ACHIEVE THIS WITHOUT LOOPING???
  i <- i + 1
}

hist(beta1_mle)
```


```{r, echo = TRUE}
hist(beta1_mle)
```

```{r, echo = TRUE}
hist(beta2_mle)
```

```{r, echo = TRUE}
hist(mu1)
```

```{r, echo = TRUE}
hist(mu2)
```

```{r, echo = TRUE}
hist(sigma1)
```

```{r, echo = TRUE}
hist(sigma2)
```

Precis som tidigare ser vi att ju fler dragningar så närmar sig histogrammen en normalfördelning vilket följer av den centrala gränsvärdessatsen.

## Uppgift 5 Log-likelihoodfunktionen för betafördelning

### a) #FRÅGA: Vadå gamma?

```{r, echo = TRUE}
llbeta <- function(par, x){
  helpsum <- 0
  i <- 1
  while(i <= length(x)) {
    helpsum <- helpsum + logb(par[1] + 1, x[i] + par[2])
    i <- i + 1
  }
  return (helpsum + length(x)*logb(par[1], par[2])) #logb är fel. ANvänd formeln som är på betadistributionens wikisida, på PDF.
}
llbeta(par = c(2, 2), x = c(0.01, 0.5, 0.99))
```

#FRÅGA: OPTIM()?, MULTIPLICERAD MED -1???

#relevant länk (med vår formel): https://stats.stackexchange.com/questions/137989/how-do-you-work-out-the-likelihood-function-for-the-beta-geometric-function

